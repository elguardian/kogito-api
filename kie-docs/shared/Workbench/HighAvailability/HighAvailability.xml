<?xml version="1.0" encoding="UTF-8"?>
<section version="5.0"
         xsi:schemaLocation="http://docbook.org/ns/docbook http://www.docbook.org/xml/5.0/xsd/docbook.xsd http://www.w3.org/1999/xlink http://www.docbook.org/xml/5.0/xsd/xlink.xsd"
         xml:base="../../" xml:id="wb.HighAvailability" xmlns="http://docbook.org/ns/docbook"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:xs="http://www.w3.org/2001/XMLSchema"
         xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xi="http://www.w3.org/2001/XInclude"
         xmlns:ns="http://docbook.org/ns/docbook">
  <title>High availability</title>

  <section xml:id="wb.vfsClustering">
    <title>VFS clustering</title>

    <para>The <link linkend="wb.VFSRepository">VFS repositories</link> (ussually git repositories) stores all the assets
    (such as rules, decision tables, process definitions, forms, etc). If that VFS resides on each local server, then it
    must be kept in sync between all servers of a cluster.</para>

    <para>Use <link xlink:href="http://zookeeper.apache.org/">Apache Zookeeper</link> and <link
    xlink:href="http://helix.incubator.apache.org/">Apache Helix</link> to accomplish this. Zookeeper glues all the
    parts together. Helix is the cluster management component that registers all cluster details (nodes, resources and
    the cluster itself). Uberfire (on top of which Workbench is build) uses those 2 components to provide VFS
    clustering.</para>

    <para>To create a VFS cluster:</para>

    <orderedlist>
      <listitem>
        <para>Download <link xlink:href="http://zookeeper.apache.org/">Apache Zookeeper</link> and <link
        xlink:href="http://helix.incubator.apache.org/">Apache Helix</link>.</para>
      </listitem>

      <listitem>
        <para>Install both:</para>

        <orderedlist>
          <listitem>
            <para>Unzip Zookeeper into a directory (<literal>$ZOOKEEPER_HOME</literal>).</para>
          </listitem>

          <listitem>
            <para>In <literal>$ZOOKEEPER_HOME</literal>, copy <literal>zoo_sample.conf</literal> to
            <literal>zoo.conf</literal></para>
          </listitem>

          <listitem>
            <para>Edit <literal>zoo.conf</literal>. Adjust the settings if needed. Usually only these 2 properties are
            relevant:</para>

            <programlisting># the directory where the snapshot is stored.
dataDir=/tmp/zookeeper
# the port at which the clients will connect
clientPort=2181</programlisting>
          </listitem>

          <listitem>
            <para>Unzip Helix into a directory (<literal>$HELIX_HOME</literal>).</para>
          </listitem>
        </orderedlist>
      </listitem>

      <listitem>
        <para>Configure the cluster in Zookeeper:</para>

        <orderedlist>
          <listitem>
            <para>Go to its <literal>bin</literal> directory:</para>

            <programlisting>$ cd $ZOOKEEPER_HOME/bin</programlisting>
          </listitem>

          <listitem>
            <para>Start the Zookeeper server:</para>

            <programlisting>$ sudo ./zkServer.sh start</programlisting>

            <para>If the server fails to start, verify that the <literal>dataDir</literal> (as specified in
            <literal>zoo.conf</literal>) is accessible.</para>
          </listitem>

          <listitem>
            <para>To review Zookeeper's activities, open <literal>zookeeper.out</literal>:</para>

            <programlisting>$ cat $ZOOKEEPER_HOME/bin/zookeeper.out</programlisting>
          </listitem>
        </orderedlist>
      </listitem>

      <listitem>
        <para>Configure the cluster in Helix: </para>

        <orderedlist>
          <listitem>
            <para>Go to its <literal>bin</literal> directory:</para>

            <programlisting>$ cd $HELIX_HOME/bin</programlisting>
          </listitem>

          <listitem>
            <para>Create the cluster:</para>

            <programlisting>$ ./helix-admin.sh --zkSvr localhost:2181 --addCluster kie-cluster</programlisting>

            <para>The <literal>zkSvr</literal> value must match the used Zookeeper server. The cluster name
            (<literal>kie-cluster</literal>) can be changed as needed.</para>
          </listitem>

          <listitem>
            <para>Add nodes to the cluster:</para>

            <programlisting># Node 1
$ ./helix-admin.sh --zkSvr localhost:2181 --addNode kie-cluster nodeOne:12345
# Node 2
$ ./helix-admin.sh --zkSvr localhost:2181 --addNode kie-cluster nodeTwo:12346
...</programlisting>

            <para>Usually the number of nodes a in cluster equal the number of application servers in the cluster. The
            node names (<literal>nodeOne:12345</literal> , ...) can be changed as needed.</para>

            <note>
              <para><literal>nodeOne:12345</literal> is the unique identifier of the node, which will be referenced
              later on when configuring application servers. It is not a host and port number, but instead it is used to
              uniquely identify the logical node.</para>
            </note>
          </listitem>

          <listitem>
            <para>Add resources to the cluster:</para>

            <programlisting>$ ./helix-admin.sh --zkSvr localhost:2181 --addResource kie-cluster vfs-repo 1 LeaderStandby AUTO_REBALANCE</programlisting>

            <para>The resource name (<literal>vfs-repo</literal>) can be changed as needed.</para>
          </listitem>

          <listitem>
            <para>Rebalance the cluster to initialize it:</para>

            <programlisting>$ ./helix-admin.sh --zkSvr localhost:2181 --rebalance kie-cluster vfs-repo 2</programlisting>
          </listitem>

          <listitem>
            <para>Start the Helix controller to manage the cluster:</para>

            <programlisting>$  ./run-helix-controller.sh --zkSvr localhost:2181 --cluster kie-cluster 2&gt;&amp;1 &gt; /tmp/controller.log &amp;</programlisting>
          </listitem>
        </orderedlist>
      </listitem>

      <listitem>
        <para>Configure the security domain correctly on the application server. For example on WildFly and JBoss
        EAP:</para>

        <orderedlist>
          <listitem>
            <para>Edit the file <literal>$JBOSS_HOME/domain/configuration/domain.xml</literal>.</para>

            <para>For simplicity sake, presume we use the default domain configuration which uses the profile
            <literal>full</literal> that defines two server nodes as part of
            <literal>main-server-group</literal>.</para>
          </listitem>

          <listitem>
            <para>Locate the profile <literal>full</literal> and add a new security domain by copying the other security
            domain already defined there by default:</para>

            <programlisting>&lt;security-domain name="kie-ide" cache-type="default"&gt;
    &lt;authentication&gt;
         &lt;login-module code="Remoting" flag="optional"&gt;
             &lt;module-option name="password-stacking" value="useFirstPass"/&gt;
         &lt;/login-module&gt;
         &lt;login-module code="RealmDirect" flag="required"&gt;
             &lt;module-option name="password-stacking" value="useFirstPass"/&gt;
         &lt;/login-module&gt;
    &lt;/authentication&gt;
&lt;/security-domain&gt;</programlisting>

            <important>
              <para>The security-domain name is a magic value.</para>
            </important>
          </listitem>
        </orderedlist>
      </listitem>

      <listitem>
        <para>Configure the <link linkend="wb.systemProperties">system properties</link> for the cluster on the
        application server. For example on WildFly and JBoss EAP:</para>

        <orderedlist>
          <listitem>
            <para>Edit the file <literal>$JBOSS_HOME/domain/configuration/host.xml</literal>.</para>
          </listitem>

          <listitem>
            <para>ocate the XML elements <literal>server</literal> that belong to the
            <literal>main-server-group</literal> and add the necessary system property.</para>

            <para>For example for nodeOne:</para>

            <programlisting language="xml">&lt;system-properties&gt;
  &lt;property name="jboss.node.name" value="nodeOne" boot-time="false"/&gt;
  &lt;property name="org.uberfire.nio.git.dir" value="/tmp/kie/nodeone" boot-time="false"/&gt;
  &lt;property name="org.uberfire.metadata.index.dir" value="/tmp/kie/nodeone" boot-time="false"/&gt;
  &lt;property name="org.uberfire.cluster.id" value="kie-cluster" boot-time="false"/&gt;
  &lt;property name="org.uberfire.cluster.zk" value="localhost:2181" boot-time="false"/&gt;
  &lt;property name="org.uberfire.cluster.local.id" value="nodeOne_12345" boot-time="false"/&gt;
  &lt;property name="org.uberfire.cluster.vfs.lock" value="vfs-repo" boot-time="false"/&gt;
  &lt;!-- If you're running both nodes on the same machine: --&gt;
  &lt;property name="org.uberfire.nio.git.daemon.port" value="9418" boot-time="false"/&gt;
&lt;/system-properties&gt;</programlisting>

            <para>And for nodeTwo:</para>

            <programlisting language="xml">&lt;system-properties&gt;
  &lt;property name="jboss.node.name" value="nodeTwo" boot-time="false"/&gt;
  &lt;property name="org.uberfire.nio.git.dir" value="/tmp/kie/nodetwo" boot-time="false"/&gt;
  &lt;property name="org.uberfire.metadata.index.dir" value="/tmp/kie/nodetwo" boot-time="false"/&gt;
  &lt;property name="org.uberfire.cluster.id" value="kie-cluster" boot-time="false"/&gt;
  &lt;property name="org.uberfire.cluster.zk" value="localhost:2181" boot-time="false"/&gt;
  &lt;property name="org.uberfire.cluster.local.id" value="nodeTwo_12346" boot-time="false"/&gt;
  &lt;property name="org.uberfire.cluster.vfs.lock" value="vfs-repo" boot-time="false"/&gt;
  &lt;!-- If you're running both nodes on the same machine: --&gt;
  &lt;property name="org.uberfire.nio.git.daemon.port" value="9419" boot-time="false"/&gt;
&lt;/system-properties&gt;</programlisting>

            <para>Make sure the cluster, node and resource names match those configured in Helix.</para>
          </listitem>
        </orderedlist>
      </listitem>
    </orderedlist>
  </section>

  <section>
    <title>jBPM clustering</title>

    <para>In addition to the information above, jBPM clustering requires additional configuration. See <link
    xlink:href="http://mswiderski.blogspot.com.br/2013/06/clustering-in-jbpm-v6.html">this blog post</link> to configure
    the database etc correctly.</para>
  </section>
</section>
